{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание\n",
    "Взять тот же датасет, который был на вебинаре и предобученную модель для задачи суммаризации\n",
    "1. Проверить насколько хорошо она суммаризирует"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
    "!wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
    "!wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
    "    assert shuffle != sort_by_date\n",
    "    records = []\n",
    "    with open(file_name, \"r\") as r:\n",
    "        for line in r:\n",
    "            records.append(json.loads(line))\n",
    "    if sort_by_date:\n",
    "        records.sort(key=lambda x: x[\"date\"])\n",
    "    if shuffle:\n",
    "        random.shuffle\n",
    "    return records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records = read_gazeta_records(\"gazeta_train.txt\")\n",
    "val_records = read_gazeta_records(\"gazeta_val.txt\")\n",
    "test_records = read_gazeta_records(\"gazeta_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "\n",
    "def calc_scores(references, predictions, metric=\"all\"):\n",
    "    print(\"Count:\", len(predictions))\n",
    "    print(\"Ref:\", references[-1])\n",
    "    print(\"Hyp:\", predictions[-1])\n",
    "\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        print(\"ROUGE: \", scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
      "Hyp: православный телеканал «спас», учредителем которого является московская патриархия, запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер в тверской области.\n",
      "BLEU:  0.19177311186434495\n",
      "ROUGE:  {'rouge-1': {'r': 0.37762764047433917, 'p': 0.22208274285774904, 'f': 0.23804097238957525}, 'rouge-2': {'r': 0.15833772153385062, 'p': 0.09647636782929753, 'f': 0.10027796832321115}, 'rouge-l': {'r': 0.34937017731940756, 'p': 0.2022959168891477, 'f': 0.21799992093276083}}\n"
     ]
    }
   ],
   "source": [
    "import razdel\n",
    "\n",
    "def calc_lead_n_score(records, summary_col = 'summary', n=3, lower=True, nrows=1000):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for i, record in enumerate(records):\n",
    "        if i >= nrows:\n",
    "            break\n",
    "\n",
    "        summary = record[summary_col]\n",
    "        summary = summary if not lower else summary.lower()\n",
    "        references.append(summary)\n",
    "\n",
    "        text = record[\"text\"]\n",
    "        text = text if not lower else text.lower()\n",
    "        sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
    "        prediction = \" \".join(sentences[:n])\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    calc_scores(references, predictions)\n",
    "\n",
    "calc_lead_n_score(test_records, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "MODEL_NAME = 'cointegrated/rut5-base-absum'\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
    "# model.cuda();\n",
    "model.eval();\n",
    "\n",
    "def summarize(\n",
    "    text, n_words=None, compression=None,\n",
    "    max_length=1000, num_beams=3, do_sample=False, repetition_penalty=10.0, \n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"\n",
    "    Summarize the text\n",
    "    The following parameters are mutually exclusive:\n",
    "    - n_words (int) is an approximate number of words to generate.\n",
    "    - compression (float) is an approximate length ratio of summary and original text.\n",
    "    \"\"\"\n",
    "    if n_words:\n",
    "        text = '[{}] '.format(n_words) + text\n",
    "    elif compression:\n",
    "        text = '[{0:.1g}] '.format(compression) + text\n",
    "    x = tokenizer(text, return_tensors='pt', padding=True).to(model.device)\n",
    "    with torch.inference_mode():\n",
    "        out = model.generate(\n",
    "            **x, \n",
    "            max_length=max_length, num_beams=num_beams, \n",
    "            do_sample=do_sample, repetition_penalty=repetition_penalty, \n",
    "            **kwargs\n",
    "        )\n",
    "    return tokenizer.decode(out[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_pred = summarize(test_records[0]['text'], len(test_records[0]['summary'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Американское аэрокосмическое агентство NASA объявило названия четырех космических миссий, которые в скором времени могут быть выбраны для реализации.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В NASA назвали четыре миссии в дальний космос, которые в этом десятилетии могут быть запущены американцами. Среди них — две миссии по изучению Венеры, полет к спутнику Юпитера и экспедиция к Тритону, спутнику Нептуна.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_records[0]['summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(test_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = df_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-47-d263e440c7d9>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_m['summary_pred'] = df_m.apply(lambda x: summarize(x['text'], len(x['summary'].split())), axis=1)\n"
     ]
    }
   ],
   "source": [
    "df_m['summary_pred'] = df_m.apply(lambda x: summarize(x['text'], len(x['summary'].split())), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>date</th>\n",
       "      <th>summary_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.gazeta.ru/science/2020/02/14_a_129...</td>\n",
       "      <td>Американское аэрокосмическое агентство NASA ог...</td>\n",
       "      <td>Венера, Ио или Тритон: куда полетит NASA</td>\n",
       "      <td>В NASA назвали четыре миссии в дальний космос,...</td>\n",
       "      <td>2020-02-14 16:39:11</td>\n",
       "      <td>Американское аэрокосмическое агентство NASA об...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.gazeta.ru/social/2020/02/28/129806...</td>\n",
       "      <td>Около 11 тысяч зрителей увидели все самое лучш...</td>\n",
       "      <td>«Люди в Бурятии очень талантливые»</td>\n",
       "      <td>25 и 26 февраля в Кремлевском дворце съездов п...</td>\n",
       "      <td>2020-02-28 10:44:13</td>\n",
       "      <td>В Бурятии прошел праздничный концерт «Танцуют ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.gazeta.ru/politics/2019/11/07_a_12...</td>\n",
       "      <td>7 ноября в Белоруссии прошли выборы членов сов...</td>\n",
       "      <td>Вспомнить СССР: как Лукашенко провел выборы</td>\n",
       "      <td>В Белоруссии в день годовщины Октябрьской рево...</td>\n",
       "      <td>2019-11-07 19:55:08</td>\n",
       "      <td>В Белоруссии впервые прошли выборы членов сове...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.gazeta.ru/culture/2020/03/01/a_129...</td>\n",
       "      <td>Народная артистка РСФСР Надежда Бабкина в инте...</td>\n",
       "      <td>«Он очень переживал»: Бабкина об отношениях с ...</td>\n",
       "      <td>Народная артистка РСФСР Надежда Бабкина в инте...</td>\n",
       "      <td>2020-03-01 16:50:06</td>\n",
       "      <td>Надежда Бабкина рассказала, как ей удалось сбр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.gazeta.ru/business/2020/02/06/1294...</td>\n",
       "      <td>Депутат Верховной рады от партии «Слуга народа...</td>\n",
       "      <td>«Поддерживают Россию»: почему Киев не платит п...</td>\n",
       "      <td>Украина не должна выплачивать пенсии жителям Д...</td>\n",
       "      <td>2020-02-06 12:41:24</td>\n",
       "      <td>В Верховной Раде раскритиковали законопроект о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.gazeta.ru/army/2019/11/13/12810158...</td>\n",
       "      <td>Журналист Питер Суппли Бенсон датского издания...</td>\n",
       "      <td>«Новый кулак в Арктике»: в Дании испугались «И...</td>\n",
       "      <td>Датского журналиста обеспокоила активность Рос...</td>\n",
       "      <td>2019-11-13 13:03:37</td>\n",
       "      <td>Журналист Питер Суппли Бенсон назвал «новым ку...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.gazeta.ru/politics/2019/10/03_a_12...</td>\n",
       "      <td>Выступление главы российской делегации Петра Т...</td>\n",
       "      <td>«Смотрите, что у вас происходит»: как прервали...</td>\n",
       "      <td>Активист сорвал выступление главы делегации РФ...</td>\n",
       "      <td>2019-10-03 20:46:08</td>\n",
       "      <td>На заседании Парламентской ассамблеи Совета Ев...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.gazeta.ru/politics/2020/01/03_a_12...</td>\n",
       "      <td>Самые известные российские пранкеры Владимир «...</td>\n",
       "      <td>Именем Греты Тунберг: Вован и Лексус разыграли...</td>\n",
       "      <td>Пранкеры Вован и Лексус разыграли члена конгре...</td>\n",
       "      <td>2020-01-03 19:25:16</td>\n",
       "      <td>Российские пранкеры Владимир «Вован» Кузнецов ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://www.gazeta.ru/culture/2019/11/06/a_127...</td>\n",
       "      <td>Российский актер и театральный педагог Виталий...</td>\n",
       "      <td>Умер актер сериала «Улицы разбитых фонарей»</td>\n",
       "      <td>Актер сериала «Улицы разбитых фонарей» Виталий...</td>\n",
       "      <td>2019-11-06 14:17:33</td>\n",
       "      <td>Российский актер Виталий Жигалин ушел из жизни...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.gazeta.ru/business/2020/01/23/1292...</td>\n",
       "      <td>Госдума одобрила в первом чтении внесенные пре...</td>\n",
       "      <td>Дождались: работающим пенсионерам восстановят ...</td>\n",
       "      <td>Работающие пенсионеры дождались индексации. Эт...</td>\n",
       "      <td>2020-01-23 19:32:12</td>\n",
       "      <td>Госдума одобрила в первом чтении поправки в Ко...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.gazeta.ru/science/2020/02/14_a_129...   \n",
       "1  https://www.gazeta.ru/social/2020/02/28/129806...   \n",
       "2  https://www.gazeta.ru/politics/2019/11/07_a_12...   \n",
       "3  https://www.gazeta.ru/culture/2020/03/01/a_129...   \n",
       "4  https://www.gazeta.ru/business/2020/02/06/1294...   \n",
       "5  https://www.gazeta.ru/army/2019/11/13/12810158...   \n",
       "6  https://www.gazeta.ru/politics/2019/10/03_a_12...   \n",
       "7  https://www.gazeta.ru/politics/2020/01/03_a_12...   \n",
       "8  https://www.gazeta.ru/culture/2019/11/06/a_127...   \n",
       "9  https://www.gazeta.ru/business/2020/01/23/1292...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Американское аэрокосмическое агентство NASA ог...   \n",
       "1  Около 11 тысяч зрителей увидели все самое лучш...   \n",
       "2  7 ноября в Белоруссии прошли выборы членов сов...   \n",
       "3  Народная артистка РСФСР Надежда Бабкина в инте...   \n",
       "4  Депутат Верховной рады от партии «Слуга народа...   \n",
       "5  Журналист Питер Суппли Бенсон датского издания...   \n",
       "6  Выступление главы российской делегации Петра Т...   \n",
       "7  Самые известные российские пранкеры Владимир «...   \n",
       "8  Российский актер и театральный педагог Виталий...   \n",
       "9  Госдума одобрила в первом чтении внесенные пре...   \n",
       "\n",
       "                                               title  \\\n",
       "0           Венера, Ио или Тритон: куда полетит NASA   \n",
       "1                 «Люди в Бурятии очень талантливые»   \n",
       "2        Вспомнить СССР: как Лукашенко провел выборы   \n",
       "3  «Он очень переживал»: Бабкина об отношениях с ...   \n",
       "4  «Поддерживают Россию»: почему Киев не платит п...   \n",
       "5  «Новый кулак в Арктике»: в Дании испугались «И...   \n",
       "6  «Смотрите, что у вас происходит»: как прервали...   \n",
       "7  Именем Греты Тунберг: Вован и Лексус разыграли...   \n",
       "8        Умер актер сериала «Улицы разбитых фонарей»   \n",
       "9  Дождались: работающим пенсионерам восстановят ...   \n",
       "\n",
       "                                             summary                 date  \\\n",
       "0  В NASA назвали четыре миссии в дальний космос,...  2020-02-14 16:39:11   \n",
       "1  25 и 26 февраля в Кремлевском дворце съездов п...  2020-02-28 10:44:13   \n",
       "2  В Белоруссии в день годовщины Октябрьской рево...  2019-11-07 19:55:08   \n",
       "3  Народная артистка РСФСР Надежда Бабкина в инте...  2020-03-01 16:50:06   \n",
       "4  Украина не должна выплачивать пенсии жителям Д...  2020-02-06 12:41:24   \n",
       "5  Датского журналиста обеспокоила активность Рос...  2019-11-13 13:03:37   \n",
       "6  Активист сорвал выступление главы делегации РФ...  2019-10-03 20:46:08   \n",
       "7  Пранкеры Вован и Лексус разыграли члена конгре...  2020-01-03 19:25:16   \n",
       "8  Актер сериала «Улицы разбитых фонарей» Виталий...  2019-11-06 14:17:33   \n",
       "9  Работающие пенсионеры дождались индексации. Эт...  2020-01-23 19:32:12   \n",
       "\n",
       "                                        summary_pred  \n",
       "0  Американское аэрокосмическое агентство NASA об...  \n",
       "1  В Бурятии прошел праздничный концерт «Танцуют ...  \n",
       "2  В Белоруссии впервые прошли выборы членов сове...  \n",
       "3  Надежда Бабкина рассказала, как ей удалось сбр...  \n",
       "4  В Верховной Раде раскритиковали законопроект о...  \n",
       "5  Журналист Питер Суппли Бенсон назвал «новым ку...  \n",
       "6  На заседании Парламентской ассамблеи Совета Ев...  \n",
       "7  Российские пранкеры Владимир «Вован» Кузнецов ...  \n",
       "8  Российский актер Виталий Жигалин ушел из жизни...  \n",
       "9  Госдума одобрила в первом чтении поправки в Ко...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import razdel\n",
    "\n",
    "def calc_lead_n_score(records, summary_col = 'summary', n=3, lower=True, nrows=1000):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for i, record in records.iterrows():\n",
    "        if i >= nrows:\n",
    "            break\n",
    "\n",
    "        summary = record[summary_col]\n",
    "        summary = summary if not lower else summary.lower()\n",
    "        references.append(summary)\n",
    "\n",
    "        text = record[\"text\"]\n",
    "        text = text if not lower else text.lower()\n",
    "        sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
    "        prediction = \" \".join(sentences[:n])\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    calc_scores(references, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 10\n",
      "Ref: работающие пенсионеры дождались индексации. это следует из уже одобренных в первом чтении поправок в конституцию. так что работающие пенсионеры смогут получить замороженную с 2016 года прибавку к пенсии. в россии их насчитывается более девяти миллионов. эксперты называют это восстановлением справедливости.\n",
      "Hyp: госдума одобрила в первом чтении внесенные президентом рф владимиром путиным поправки в конституцию. в его основу легли предложения, которые президент россии владимир путин озвучил в послании федеральному собранию. одно из них — регулярная индексация, формирование системы пенсионного обеспечения граждан россии «на основе принципов всеобщности, справедливости и солидарности поколений». сопредседатель профильной рабочей группы по конституции россии талия хабриева пояснила, что поправка об индексации пенсий распространяется и на работающих пенсионеров. по словам хабриевой, само правило сформулировано без изъятий, и возможна только конкретизация порядка в федеральном законе. о том, что из нынешних поправок в конституцию проистекает и индексация пенсий работающим пенсионерам, заявил и депутат госдумы олег шеин. по его словам, увеличение выплат для работающих пенсионеров будет производиться автоматически. для этого не нужно даже писать заявление. по словам депутата, оно может быть принято уже в конце марта. индексация пенсий всем работающим пенсионерам, в том числе с инвалидностью, не производится с 2016 года. и менять это решение в правительстве не собирались до последнего времени. в 2017 году министр финансов антон силуанов предлагал вернуться к вопросу об индексации таких пенсий в 2020 году. в октябре 2019 года антон дроздов , возглавлявший тогда пфр , говорил, что на это нет денег. на возобновление индексации пенсий работающим пенсионерам в 2020 году потребовалось бы 368 млрд рублей, отмечал он. «поправками в конституцию закрепляется то, что государство готово выполнять свои обязательства и в тяжелые для пенсионной системы годы. однако, во-первых, уже сейчас по закону индексация выплат предусмотрена. предложение закрепить ее на уровне конституции — это констатация уже существующих норм и подчеркнутое подтверждение исполнения государством своих обязательств. во-вторых, индексация работающим пенсионерам производится и сейчас, но перерасчет производится без фактической выплаты. только после выхода на заслуженный отдых с рабочего места официально появляется право на получение ранее накопленных уже в период выдачи средств с индивидуального счета», — говорит независимый пенсионный консультант сергей звенигородский. по словам вячеслава абрамова, директора офиса продаж « бкс брокер », в прошлом году была проведена пенсионная реформа, которой многие остались недовольны. она закрепила, что в ходу нее поэтапно будет повышен возраст получения выплат от государства. реформа началась с 2019 года. если раньше возраст выхода на заслуженный отдых составлял 55 лет для женщин и 60 лет для мужчин, то с 2019 года он постепенно увеличивается — в среднем на полгода каждый год. к 2028 году порог достигнет 60 лет для женщин и 65 лет для мужчин. благодаря ней, количество людей, получающих пенсию, снизилось. соответственно, пфр сэкономил деньги. «решение вернуть индексацию выплат работающим пенсионерам может быть принято именно сейчас, потому что оно ранее сильно повлияло на рейтинги власти. вероятнее всего, дополнительные средства будут изыскивать за счет снижения льгот для нефтегазового сектора экономики, введения налога на добычу полезных ископаемых для попутного нефтяного газа, который ранее налогом не облагался, а также за счет улучшения собираемости ндфл», — говорит павел сигал первый вице президент «опоры россии». по его словам, работающих пенсионеров насчитывается 9,6 млн из 43 млн зарегистрированных. это около 8,5% электората. «индексация пенсий работающим пенсионерам – справедливая и необходимая мера. не должно быть различия между теми, кто имеет занятость и не работает. пенсия — это выплата людям, достигшим установленного возраста. поэтому лишение работающих лиц пожилого возраста индексации по принципу «у них и так есть, на что жить» — совершенно неприемлемо», — говорит иван капустянский , ведущий аналитик forex optimum. по мнению эксперта, деньги на индексацию вряд ли будут взяты из фонда национального благосостояния ( фнб ). «да, он будет «распечатан», как предполагается, в 2020 году при превышении им установленных бюджетным кодексом 7% ввп. но данные средства могут быть использованы лишь на инвестиционные, инфраструктурные проекты, но не на социальные выплаты. но источники могут быть иными. частично внутри самого пфр за счет уменьшения выплат из-за роста пенсионного возраста. по этой причине в 2020 году, как сообщил пфр, не выйдут на пенсию 800 тыс. россиян. помимо этого, традиционно пфр пополняется из госбюджета. его профицит, то есть избыток средств, составит в 2020 году 876 млрд руб.», — говорит эксперт.\n",
      "BLEU:  0.056532340101857946\n",
      "ROUGE:  {'rouge-1': {'r': 0.5963523908872423, 'p': 0.05683725425525643, 'f': 0.10335114779592154}, 'rouge-2': {'r': 0.2376237693503361, 'p': 0.017972741243862382, 'f': 0.03329939123868465}, 'rouge-l': {'r': 0.5698811307351802, 'p': 0.054439684782922035, 'f': 0.09897210313800238}}\n"
     ]
    }
   ],
   "source": [
    "calc_lead_n_score(df_m, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 10\n",
      "Ref: госдума одобрила в первом чтении поправки в конституцию россии. она закрепила, что государство готово выполнять своие обязательства\n",
      "Hyp: госдума одобрила в первом чтении внесенные президентом рф владимиром путиным поправки в конституцию. в его основу легли предложения, которые президент россии владимир путин озвучил в послании федеральному собранию. одно из них — регулярная индексация, формирование системы пенсионного обеспечения граждан россии «на основе принципов всеобщности, справедливости и солидарности поколений». сопредседатель профильной рабочей группы по конституции россии талия хабриева пояснила, что поправка об индексации пенсий распространяется и на работающих пенсионеров. по словам хабриевой, само правило сформулировано без изъятий, и возможна только конкретизация порядка в федеральном законе. о том, что из нынешних поправок в конституцию проистекает и индексация пенсий работающим пенсионерам, заявил и депутат госдумы олег шеин. по его словам, увеличение выплат для работающих пенсионеров будет производиться автоматически. для этого не нужно даже писать заявление. по словам депутата, оно может быть принято уже в конце марта. индексация пенсий всем работающим пенсионерам, в том числе с инвалидностью, не производится с 2016 года. и менять это решение в правительстве не собирались до последнего времени. в 2017 году министр финансов антон силуанов предлагал вернуться к вопросу об индексации таких пенсий в 2020 году. в октябре 2019 года антон дроздов , возглавлявший тогда пфр , говорил, что на это нет денег. на возобновление индексации пенсий работающим пенсионерам в 2020 году потребовалось бы 368 млрд рублей, отмечал он. «поправками в конституцию закрепляется то, что государство готово выполнять свои обязательства и в тяжелые для пенсионной системы годы. однако, во-первых, уже сейчас по закону индексация выплат предусмотрена. предложение закрепить ее на уровне конституции — это констатация уже существующих норм и подчеркнутое подтверждение исполнения государством своих обязательств. во-вторых, индексация работающим пенсионерам производится и сейчас, но перерасчет производится без фактической выплаты. только после выхода на заслуженный отдых с рабочего места официально появляется право на получение ранее накопленных уже в период выдачи средств с индивидуального счета», — говорит независимый пенсионный консультант сергей звенигородский. по словам вячеслава абрамова, директора офиса продаж « бкс брокер », в прошлом году была проведена пенсионная реформа, которой многие остались недовольны. она закрепила, что в ходу нее поэтапно будет повышен возраст получения выплат от государства. реформа началась с 2019 года. если раньше возраст выхода на заслуженный отдых составлял 55 лет для женщин и 60 лет для мужчин, то с 2019 года он постепенно увеличивается — в среднем на полгода каждый год. к 2028 году порог достигнет 60 лет для женщин и 65 лет для мужчин. благодаря ней, количество людей, получающих пенсию, снизилось. соответственно, пфр сэкономил деньги. «решение вернуть индексацию выплат работающим пенсионерам может быть принято именно сейчас, потому что оно ранее сильно повлияло на рейтинги власти. вероятнее всего, дополнительные средства будут изыскивать за счет снижения льгот для нефтегазового сектора экономики, введения налога на добычу полезных ископаемых для попутного нефтяного газа, который ранее налогом не облагался, а также за счет улучшения собираемости ндфл», — говорит павел сигал первый вице президент «опоры россии». по его словам, работающих пенсионеров насчитывается 9,6 млн из 43 млн зарегистрированных. это около 8,5% электората. «индексация пенсий работающим пенсионерам – справедливая и необходимая мера. не должно быть различия между теми, кто имеет занятость и не работает. пенсия — это выплата людям, достигшим установленного возраста. поэтому лишение работающих лиц пожилого возраста индексации по принципу «у них и так есть, на что жить» — совершенно неприемлемо», — говорит иван капустянский , ведущий аналитик forex optimum. по мнению эксперта, деньги на индексацию вряд ли будут взяты из фонда национального благосостояния ( фнб ). «да, он будет «распечатан», как предполагается, в 2020 году при превышении им установленных бюджетным кодексом 7% ввп. но данные средства могут быть использованы лишь на инвестиционные, инфраструктурные проекты, но не на социальные выплаты. но источники могут быть иными. частично внутри самого пфр за счет уменьшения выплат из-за роста пенсионного возраста. по этой причине в 2020 году, как сообщил пфр, не выйдут на пенсию 800 тыс. россиян. помимо этого, традиционно пфр пополняется из госбюджета. его профицит, то есть избыток средств, составит в 2020 году 876 млрд руб.», — говорит эксперт.\n",
      "BLEU:  0.023488786151578293\n",
      "ROUGE:  {'rouge-1': {'r': 0.8865338827838827, 'p': 0.030610343510517873, 'f': 0.058975649146975374}, 'rouge-2': {'r': 0.7280000571324101, 'p': 0.017236213947088668, 'f': 0.03357399959641017}, 'rouge-l': {'r': 0.8865338827838827, 'p': 0.030610343510517873, 'f': 0.058975649146975374}}\n"
     ]
    }
   ],
   "source": [
    "calc_lead_n_score(df_m, summary_col = 'summary_pred', n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вывод: Метрика на сгенерированных заголовках заметно хуже"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.(дополнительно) Сделать генерацию заголовков для статьи (обучить модель для генерации заголовков)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs:\n",
    "- https://huggingface.co/docs/transformers/main/en/notebooks\n",
    "- https://github.com/huggingface/notebooks/blob/main/examples/summarization.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_records)\n",
    "df_eval = pd.DataFrame(val_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n",
    "    prefix = \"summarize: \"\n",
    "else:\n",
    "    prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/cointegrated/rut5-base-absum/resolve/main/spiece.model from cache at /Users/maximdoroshenko/.cache/huggingface/transformers/8a1eac3ebf60aa372c248f6a0c1746950e53dbe4854a6c7da4214a232b8d7ef3.b846524fbcbf3cf81e2302f8087043922ca4c445b4016bf16e707f7e2240a3e6\n",
      "loading file https://huggingface.co/cointegrated/rut5-base-absum/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cointegrated/rut5-base-absum/resolve/main/special_tokens_map.json from cache at /Users/maximdoroshenko/.cache/huggingface/transformers/0580647d92af8f2d54e8e5246c0f1d4a915857e12f8b5b329cbc2b10aecd5715.294ebaa4cd17bb284635004c92d2c4d522ec488c828dcce0c2471b6f28e3fe82\n",
      "loading file https://huggingface.co/cointegrated/rut5-base-absum/resolve/main/tokenizer_config.json from cache at /Users/maximdoroshenko/.cache/huggingface/transformers/261c267054279f7a8a33af270db14f22624d21d277016abcb4019ef5e179b2f5.2dd03d206e8192151f6174bd84b39de784ed51f39735f40fdff39fa02be87a84\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"summary\"].to_list(), max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# preprocess_function(df_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df_train = preprocess_function(df_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df_eval = preprocess_function(df_eval[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/cointegrated/rut5-base-absum/resolve/main/config.json from cache at /Users/maximdoroshenko/.cache/huggingface/transformers/f1a153bb308fca4a2a02f4051ed80cf69897520df9b453f54367821e24a37a38.7f4839e0529489637e46ac6b0406b7d092cbda7090828c963dd6ffdd795da468\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"/gd/MyDrive/models/rut5-base-absum\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForConditionalGeneration\"\n",
      "  ],\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"T5Tokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/cointegrated/rut5-base-absum/resolve/main/pytorch_model.bin from cache at /Users/maximdoroshenko/.cache/huggingface/transformers/f7612f7949123ac8cd36a9bd833bf690cd8a3e0770cef65f71d56f9741ebeb1e.d87c2fb74c13c233875af435140e11d87df62cf59ca997a0a8df4bc85d041773\n",
      "All model checkpoint weights were used when initializing T5ForConditionalGeneration.\n",
      "\n",
      "All the weights of T5ForConditionalGeneration were initialized from the model checkpoint at cointegrated/rut5-base-absum.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-xsum\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True,\n",
    "#     fp16=True,\n",
    "#     push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_df_train,\n",
    "    eval_dataset=tokenized_df_eval,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 3\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-239-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         )\n\u001b[0;32m-> 1317\u001b[0;31m         return inner_training_loop(\n\u001b[0m\u001b[1;32m   1318\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m             raise KeyError(\n\u001b[0m\u001b[1;32m    241\u001b[0m                 \u001b[0;34m\"Indexing with integers (to access backend Encoding for a given batch index) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0;34m\"is not available when using Python based tokenizers\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Indexing with integers (to access backend Encoding for a given batch index) is not available when using Python based tokenizers'"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
